## 多项式回归

### 1. 引入

- 线性回归要求线性关系，这要求较高；
- 多项式回归适用于非线性关系的数据；

### 2. 概要

将原来的数据样本通过**多项式组合**添加新的特征，本质上是**升维**的过程。

假设原来的数据集是$X$，而已知样本与标签满足某种二次关系，我们可以如下构造$X'$ ：
$$
X' = [X,~X^2]
$$
再对于 $X'$ 运用线性回归法即可求出不同维度对应的特征值。如果 $X$ 包含多个特征，则对于任意两个特征都要构造出对应的二阶特征（如 $x_1,x_2$ 的二阶特征对应 $x_1^2, x_2^2, x_1x_2$ ）。

例如，对于 `y=0.5*x**2 + x*2 + np.random.normal(0,1,100)` 这种数据集：

```python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree = 2)
poly.fit(X)
X2 = poly.transform(X) #  将原数据集升维
X2.shape
#>>>(100, 3) 对应的是 0~2 维的系数
```

```py
from sklearn.linear_model import LinearRegression
lin_reg2 = LinearRegression()
lin_reg2.fit(X2, y)
y_prd2 = lin_reg2.predict(X2) # 通过多项式回归模型，进行训练和预测
```

如果多项式回归的阶数很高，那么生成新的样本数据之间的差距就会很大（如 `1^1 `与 `10^10`）。因此有必要进行**数据归一化**，再用以训练线性回归模型。

我们可以通过 `sklearn.pipeline` 库进行流水线封装操作，可参考 `pipeline_test.ipynb `。



### 3. 过拟合与欠拟合

> 在很多情况下，我们可以 学得一个经验误差很小、在训练集上表现很好的学习器，例如甚至对所有训练 样本都分类正确，即分类错误率为零，分类精度为 100% ，但这是不是我们想要 的学习器呢？遗憾的是，这样的学习器在多数情况下都不好.

我们实际希望的，是**在新的样本上也能表现得很好**的学习器。为了达到这个目的，应该从训练样本中尽可能学出适用于**所有潜在样本的"普遍规律"**，这 样才能在遇到新样本时做出正确的判别。

如果对于训练数据集，其分类的精度过高（或者称**多项式回归的阶数过高**），此时很可能巳经把训练样本自身的一些特点（如噪音）当作了所有潜在样本都会具有的一般性质，这样就会导致**泛化性能下降（即普遍规律）**。这种现象在机器学习中称为 **"过拟合" （overfitting）**。

.关于这一点，可大致这样理解：机器学习面临的问题通常是 **NP 问题甚至更难**，而有效的学习算法必然是在多项式时间内得到的。若要彻底避免过拟合， 通过经验误差最小化就能获最优解，这就意 味着我们**构造性地证明了"P=NP"**。这与一般结论是相悖的。

为了评估机器学习模型是否过拟合/欠拟合，我们引入**学习曲线**的概念。学习曲线是将**训练集误差和测试集误差**为纵轴，**训练集实例数量** $m$ 为横轴的的函数绘制图表。当两者之前的差距过大时，我们认为这个模型是过拟合的。

为了评估一个模型是否过拟合or欠拟合，我们可以利用训练测试数据集分离的方式评定其泛化误差。一般来说，**随着模型复杂程度提高**，对测试数据集的预测准确率一般**先提高后降低**。具体代码可参考 `Overfitting_test.ipynb`。



![image-20230121170630651](C:\Users\14927\AppData\Roaming\Typora\typora-user-images\image-20230121170630651.png)



### 4. 交叉验证法

简单的`训练-测试`数据集分离根据测试数据集的拟合程度进行评判，这可能会导致模型**虽然没有过拟合训练数据集、但过拟合了测试数据集**的情况。因此，`sklearn` 还采用了`训练-验证-测试`数据集分离的方法，即验证数据集担任了原来测试数据集的效用，而测试数据仅在最后评判性能的时候使用。

除此之外，为了避免因数据分布的随机性导致模型训练的不够泛化，可以采取**交叉验证**的方法：即将数据分为 K 个大小相似的互斥子集，每次**用 K-1 子集的并作为训练集，而余下的那个子集作验证集**。这样就可获得 K 组`训练-测试`集，最终返回的是 K 次测试结果的均值。

![image-20230121164657079](C:\Users\14927\AppData\Roaming\Typora\typora-user-images\image-20230121164657079.png)



可以简单写一段代码去模拟该过程：

```py
from sklearn.model_selection import cross_val_score

knn_clf = KNeighborClassifier()
scores = cross_val_score(knn_clf, X_train, y_train)
score = np.mean(scores)
# 默认 cv=3，把训练集分成三份
# >>> array([0.98, 0.97, 0.96])
```



### 5. 偏差方差平衡

一张图理解偏差与方差，令$E(f;D)$表示模型 f 关于数据集 D 的期望误差：

- 偏差（`Bias`）指的是平均预测值与真实标记值之间的期望距离；
- 方差（`Varience`）指的是不同训练集得到的预测值之间的期望距离；

![image-20230121165354119](C:\Users\14927\AppData\Roaming\Typora\typora-user-images\image-20230121165354119.png)



一般来说，模型误差有三方面组成：偏差、方程与不可避免误差。
$$
E(f;D) = Bias^2(x) + Var(x) + \varepsilon^2
$$
其中 $\varepsilon^2$ 表示模型训练过程中不可避免的误差（如噪音）。我们认为**欠拟合**是导致偏差的原因（如特征与标记不相干、或者算法选取有误），模型太过复杂（**过拟合**）则会导致方差。

非参数学习的算法通常都为高方差算法，他们对数据的依赖较高、对数据敏感；参数学习（如线性回归）对数据有极强的假设性，从而导致较高的偏差。可以通过调节超参数或者模型的阶数来降低偏差和方差误差。

一般为了解决过拟合而导致的高方差，我们有如下手段：

- 降低模型复杂度（`degree`）
- **主成分降噪处理**
- 增加样本数
- **模型正则化**



### 6. 模型正则化

我们构建回归模型解决问题，实质上就是找一组参数，使得$J(\theta) = MSE(y, \hat{y};\theta)$ 尽可能小；然而如果模型过拟合，那一组参数 $\theta$ 很大也不是我们想要的。因此我们引入模型正则化，将损失函数改为：
$$
J(\theta) = MSE(y, \hat{y};\theta) + \alpha\sum_{i=1}^m\theta_i^2
$$
这样的话，要使 $J(\theta)$ 尽可能小，就要综合考虑两项，对于第二项来说，是 $\theta_i$ 的二次项，因此我们要考虑让参数尽可能小从而施加限制，通常称作 $L2$ 正则化，也被称为**“岭回归”**。

同理，如果把后面那项换成绝对值，那就属于 $L1$ 正则化，又称为**"LASSO回归"**。实践中也可以类比岭回归的用法，去调整 $\alpha$ 的参数从而训练正则化模型。

在实际操作中我们发现，当逐渐增大 $\alpha$ 在式子中的比重， 岭回归倾向于**平均地降低 $\theta_i$ 中每一项的大小**，使得模型更为平滑；而 LASSO 回归则倾向于将部分 $\theta_i$ 的值变为 0，通过**筛选特征**的方式来解决模型泛化问题。究其原因， 可以从两种回归的梯度式中分析。

利用岭回归和 LASSO 回归对模型进行正则化的详细代码可见 `Regularization_test.ipynb`。

同理，同时包含 L1 正则与 L2 正则的损失函数被称为**弹性网**，可以同时结合两者的优势。因此优先选择岭回归，其次选择弹性网的模型：$J(\theta) = MSE(y, \hat{y};\theta) + r\alpha\sum_{i=1}^m|\theta_i|+ \frac{1-r}{2}\alpha\sum_{i=1}^m\theta_i^2$ .
